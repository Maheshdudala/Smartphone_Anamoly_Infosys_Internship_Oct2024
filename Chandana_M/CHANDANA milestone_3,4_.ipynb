{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fbe3413-a785-4b18-904a-6351bd08f13d",
   "metadata": {},
   "source": [
    "## Task 3: Document Model Response under High-Stress Scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25859af7-3a88-4fe2-9316-2701d8fd7833",
   "metadata": {},
   "source": [
    "## Anomaly Detection Stress Testing Report\n",
    "\n",
    "### Overview\n",
    "This report assesses the performance of two anomaly detection models—**Isolation Forest** and **Local Outlier Factor (LOF)**—under both normal and high-stress conditions. The stress testing was conducted by injecting high-frequency anomalies into the dataset and evaluating how well each model identified these anomalies. The goal was to simulate extreme conditions to test the robustness of each model in identifying both natural and synthetic anomalies.\n",
    "\n",
    "### Baseline Performance (Original Data)\n",
    "\n",
    "For the baseline data, the following metrics were recorded for both models without any additional stress-induced anomalies:\n",
    "\n",
    "- **Isolation Forest:**\n",
    "  - **Accuracy**: 96%\n",
    "  - **Precision**: 14%\n",
    "  - **Recall**: 100%\n",
    "  - **F1 Score**: 24%\n",
    "\n",
    "- **Local Outlier Factor (LOF):**\n",
    "  - **Accuracy**: 96%\n",
    "  - **Precision**: 14%\n",
    "  - **Recall**: 100%\n",
    "  - **F1 Score**: 24%\n",
    "\n",
    "The baseline performance metrics show that both models have a high accuracy but a low precision. High recall values of 100% indicate that the models captured all true anomalies in the dataset, but the low precision suggests that there were many false positives, impacting the models' effectiveness in distinguishing true anomalies from normal data points.\n",
    "\n",
    "### Performance on Stressed Data\n",
    "\n",
    "To simulate high-stress conditions, synthetic anomalies were introduced into the dataset at regular intervals, creating high-frequency extreme values. This stressed dataset was used to measure each model's ability to detect anomalies under these challenging conditions.\n",
    "\n",
    "#### Isolation Forest - Detection Rates on Stressed Data\n",
    "\n",
    "- **Accuracy**: 95.66%\n",
    "- **Precision**: 13.65%\n",
    "- **Recall**: 98%\n",
    "- **F1 Score**: 23.96%\n",
    "\n",
    "#### Local Outlier Factor (LOF) - Detection Rates on Stressed Data\n",
    "\n",
    "- **Accuracy**: 95.65%\n",
    "- **Precision**: 13.51%\n",
    "- **Recall**: 97%\n",
    "- **F1 Score**: 23.72%\n",
    "\n",
    "### Analysis and Observations\n",
    "\n",
    "1. **Accuracy**: Both models saw a slight drop in accuracy (from 96% to around 95.65%) when stressed with synthetic anomalies, suggesting that the models were able to maintain a high level of overall performance. However, this slight decrease indicates that some of the synthetic anomalies impacted model decisions on a subset of normal points.\n",
    "\n",
    "2. **Precision**: Precision dropped marginally for both models (Isolation Forest from 14% to 13.65% and LOF from 14% to 13.51%) under stressed conditions. This reduction in precision suggests an increase in false positive rates, where the models may have mistakenly labeled more normal data points as anomalies under high-stress scenarios.\n",
    "\n",
    "3. **Recall**: Recall slightly decreased for both models under stress, with Isolation Forest reducing to 98% and LOF to 97%. This small reduction implies that, although most anomalies were still detected, a few synthetic anomalies introduced during stress testing were missed. Given the high frequency of synthetic anomalies, this decrease in recall reflects the challenges introduced by extreme values and dense anomaly points.\n",
    "\n",
    "4. **F1 Score**: Both models experienced a minor decrease in F1 scores under stress. The F1 score for Isolation Forest dropped from 24% to 23.96%, and for LOF, it decreased from 24% to 23.72%. This slight change suggests that both models handled high-stress conditions fairly well, despite the additional anomalies.\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "- **Robustness Under Stress**: Isolation Forest and LOF models demonstrated robust performance under high-stress conditions, as evidenced by only a minor decrease in accuracy and recall. The slight decrease in precision and F1 score indicates an increased sensitivity to extreme anomalies, resulting in more false positives but maintaining overall anomaly detection.\n",
    "\n",
    "- **Model Suitability**: Isolation Forest and LOF both performed comparably under high-stress scenarios. The choice between the two models may depend on application requirements, as Isolation Forest showed marginally higher recall, while LOF had a similar F1 score with a slight computational efficiency advantage.\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. **Optimization**: To enhance precision and F1 scores, hyperparameter tuning (e.g., varying contamination levels) could improve precision, especially under high-frequency anomaly scenarios.\n",
    "  \n",
    "2. **Hybrid Models**: Combining Isolation Forest and LOF, or utilizing an ensemble model, could enhance robustness by leveraging the complementary strengths of each model.\n",
    "\n",
    "3. **Further Testing**: Conduct additional stress tests by varying the magnitude and frequency of synthetic anomalies to observe model adaptability under more diverse conditions.\n",
    "\n",
    "In summary, both Isolation Forest and LOF demonstrated resilience to stress-induced anomalies with only minor variations in performance metrics, supporting their applicability in real-world anomaly detection scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c18eb27-2998-4be3-b764-287e73b83302",
   "metadata": {},
   "source": [
    "DAY 12\n",
    "## Stress Test Results Documentation\n",
    "\n",
    "### 1. Summary of Key Findings\n",
    "\n",
    "Stress testing was conducted on two primary anomaly detection models: **Isolation Forest** and **Local Outlier Factor (LOF)**. Each model was evaluated under both normal and stressed conditions to assess their performance and robustness. The stressed dataset included high-frequency synthetic anomalies introduced at regular intervals, simulating extreme conditions.\n",
    "\n",
    "#### Key Findings:\n",
    "\n",
    "- **Accuracy**: Both models maintained high accuracy under stress, decreasing slightly from 96% to approximately 95.65%, indicating resilience against synthetic anomalies.\n",
    "- **Precision**: Both models experienced a minor decrease in precision. Isolation Forest’s precision fell from 14% to 13.65%, and LOF’s precision dropped from 14% to 13.51%. This suggests an increased rate of false positives under stressed conditions.\n",
    "- **Recall**: The recall values dropped slightly, with Isolation Forest at 98% and LOF at 97%. The minor decrease indicates that the models missed a few synthetic anomalies, but both maintained strong recall rates.\n",
    "- **F1 Score**: Both models’ F1 scores showed minimal reductions, with Isolation Forest decreasing from 24% to 23.96% and LOF from 24% to 23.72%. This slight change indicates that each model handled the high-stress environment reasonably well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb5d1e1-812a-4431-adfe-c3b9d978f135",
   "metadata": {},
   "source": [
    "## Group 4: 06.11.2024\n",
    "\n",
    "DAY 13 -- CHANDANA M -- OUTPUT\n",
    "\n",
    "### 1. Code to Test Model Performance Against Different Types of Simulated Anomalies\n",
    "\n",
    "  \n",
    "### Explanation of Code:\n",
    "\n",
    "1. **Simulate Anomalies**: The `simulate_anomalies` function allows us to introduce four types of anomalies in the dataset: spikes, drifts, drops, and noise.\n",
    "2. **Model Setup**: Isolation Forest and LOF models are initialized.\n",
    "3. **Performance Metrics Calculation**: Each model's performance is evaluated using `accuracy`, `precision`, `recall`, and `f1 score` for every type of simulated anomaly.\n",
    "4. **Result Logging**: Results are stored in a DataFrame and printed for analysis. \n",
    "\n",
    "This code provides a structured approach to testing model performance across various simulated anomaly types, documenting their ability to identify anomalies under different stress conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3048ccbd-b7b3-48da-a151-17467a9f7cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\disha\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\disha\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\disha\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\disha\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance with Different Types of Simulated Anomalies:\n",
      "               Model Anomaly Type  Accuracy  Precision    Recall  F1 Score\n",
      "0  Isolation Forest        spike  0.870905   0.208914  0.104603  0.139405\n",
      "1               LOF        spike  0.875296   0.223950  0.100418  0.138662\n",
      "2  Isolation Forest        drift  0.870626   0.206128  0.103208  0.137546\n",
      "3               LOF        drift  0.868744   0.158295  0.072524  0.099474\n",
      "4  Isolation Forest         drop  0.878015   0.279944  0.140167  0.186803\n",
      "5               LOF         drop  0.867838   0.148936  0.068340  0.093690\n",
      "6  Isolation Forest        noise  0.871881   0.218663  0.109484  0.145911\n",
      "7               LOF        noise  0.873554   0.197452  0.086471  0.120272\n"
     ]
    }
   ],
   "source": [
    "# DAY 13\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Original Data Setup\n",
    "data = augmented_data.copy()\n",
    "features = ['Acc X', 'Acc Y', 'Acc Z', 'gyro_x', 'gyro_y', 'gyro_z']  # Define feature columns for models\n",
    "data['anomaly'] = 0  # Initialize anomaly column for simulated data\n",
    "\n",
    "# Function to Simulate Different Types of Anomalies\n",
    "def simulate_anomalies(data, feature, anomaly_type=\"spike\", magnitude=10, frequency=0.05):\n",
    "    data_sim = data.copy()\n",
    "    anomaly_indices = np.random.choice(data_sim.index, int(frequency * len(data_sim)), replace=False)\n",
    "    \n",
    "    if anomaly_type == \"spike\":\n",
    "        data_sim.loc[anomaly_indices, feature] += magnitude * np.random.randn(len(anomaly_indices))\n",
    "    elif anomaly_type == \"drift\":\n",
    "        data_sim.loc[anomaly_indices, feature] += np.linspace(0, magnitude, len(anomaly_indices))\n",
    "    elif anomaly_type == \"drop\":\n",
    "        data_sim.loc[anomaly_indices, feature] = data_sim[feature].min()\n",
    "    elif anomaly_type == \"noise\":\n",
    "        data_sim.loc[anomaly_indices, feature] += magnitude * np.random.uniform(-1, 1, len(anomaly_indices))\n",
    "    \n",
    "    data_sim.loc[anomaly_indices, 'anomaly'] = 1\n",
    "    return data_sim\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {\"Model\": [], \"Anomaly Type\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1 Score\": []}\n",
    "\n",
    "# Types of anomalies to test\n",
    "anomaly_types = [\"spike\", \"drift\", \"drop\", \"noise\"]\n",
    "\n",
    "# Isolation Forest and LOF Setup\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05, novelty=True)\n",
    "\n",
    "for anomaly_type in anomaly_types:\n",
    "    # Simulate anomalies\n",
    "    simulated_data = simulate_anomalies(data, feature='Acc X', anomaly_type=anomaly_type, magnitude=10, frequency=0.1)\n",
    "\n",
    "    # Isolation Forest Model Evaluation\n",
    "    iso_forest.fit(simulated_data[features])\n",
    "    iso_preds = iso_forest.predict(simulated_data[features])\n",
    "    iso_preds = (iso_preds == -1).astype(int)\n",
    "    \n",
    "    accuracy_iso = accuracy_score(simulated_data['anomaly'], iso_preds)\n",
    "    precision_iso = precision_score(simulated_data['anomaly'], iso_preds)\n",
    "    recall_iso = recall_score(simulated_data['anomaly'], iso_preds)\n",
    "    f1_iso = f1_score(simulated_data['anomaly'], iso_preds)\n",
    "    \n",
    "    # Log Isolation Forest results\n",
    "    results[\"Model\"].append(\"Isolation Forest\")\n",
    "    results[\"Anomaly Type\"].append(anomaly_type)\n",
    "    results[\"Accuracy\"].append(accuracy_iso)\n",
    "    results[\"Precision\"].append(precision_iso)\n",
    "    results[\"Recall\"].append(recall_iso)\n",
    "    results[\"F1 Score\"].append(f1_iso)\n",
    "\n",
    "    # LOF Model Evaluation\n",
    "    lof.fit(simulated_data[features])\n",
    "    lof_preds = lof.predict(simulated_data[features])\n",
    "    lof_preds = (lof_preds == -1).astype(int)\n",
    "    \n",
    "    accuracy_lof = accuracy_score(simulated_data['anomaly'], lof_preds)\n",
    "    precision_lof = precision_score(simulated_data['anomaly'], lof_preds)\n",
    "    recall_lof = recall_score(simulated_data['anomaly'], lof_preds)\n",
    "    f1_lof = f1_score(simulated_data['anomaly'], lof_preds)\n",
    "    \n",
    "    # Log LOF results\n",
    "    results[\"Model\"].append(\"LOF\")\n",
    "    results[\"Anomaly Type\"].append(anomaly_type)\n",
    "    results[\"Accuracy\"].append(accuracy_lof)\n",
    "    results[\"Precision\"].append(precision_lof)\n",
    "    results[\"Recall\"].append(recall_lof)\n",
    "    results[\"F1 Score\"].append(f1_lof)\n",
    "\n",
    "# Convert results to DataFrame for readability\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Model Performance with Different Types of Simulated Anomalies:\\n\", results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb209eb2-1b14-4843-9535-a086cd8a056f",
   "metadata": {},
   "source": [
    "## Group 4: 08.11.2024 \n",
    "DAY 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b42c8f-aeb7-4071-a1f0-b050c0b534bf",
   "metadata": {},
   "source": [
    "DAY 14\n",
    "\n",
    "## Final Report on Simulation and Stress Testing of Anomaly Detection Models\n",
    "\n",
    "### 2.4 Test Alternative Density-Based Techniques\n",
    "\n",
    "Incorporating techniques like **DBSCAN** or **Extended LOF** could increase robustness in areas with dense anomaly clusters. These density-based methods are more sensitive to local data variations, enabling them to detect densely packed anomalies without misclassifying benign data.\n",
    "\n",
    "### 2.5 Utilize Incremental Learning Techniques\n",
    "\n",
    "Incremental learning approaches allow models to adapt to evolving anomaly patterns over time. Training the models to recognize gradual changes could improve their performance under scenarios where data distributions shift dynamically.\n",
    "\n",
    "### 2.6 Explore Advanced Detection Thresholding\n",
    "\n",
    "Applying dynamic thresholding based on contextual or seasonal variations could improve anomaly detection accuracy. For example, adjusting thresholds during high-fluctuation periods could help models focus on significant anomalies, thus reducing false positives.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3aeb93-1d31-438a-8ede-e7c68b973c3c",
   "metadata": {},
   "source": [
    "DAY 15\n",
    "## 11.11.24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d269c1-e130-4e4d-8eb7-fc4f7f3d2824",
   "metadata": {},
   "source": [
    "DAY 15\n",
    "## Tasks done by Group 4\n",
    "\n",
    "### LOF (Local Outlier Factor) Model Tasks:\n",
    "1. **Outlier Validation and Threshold Adjustments**:\n",
    "   - **Analyze False Positives/Negatives**: Identified patterns in false positives and negatives detected by IQR and Z-Score.\n",
    "   - **Threshold Optimization**: Suggested optimal combinations of IQR and Z-Score thresholds to minimize false positives and negatives.\n",
    "   - **Exploration of Alternative Methods**: Investigated alternative methods, such as Mahalanobis Distance and Robust Covariance Estimation, for potentially more effective outlier detection.\n",
    "\n",
    "2. **Hyperparameter Tuning**:\n",
    "   - **Research Hyperparameters**: Examined key hyperparameters for LOF, such as `n_neighbors` and `contamination`, to understand their impact on performance.\n",
    "   - **Experimentation and Tuning**: Implemented tuning strategies, potentially adjusting hyperparameters based on observed results and analysis of detection performance.\n",
    "\n",
    "---\n",
    "\n",
    "### Isolation Forest Model Tasks:\n",
    "1. **Data Augmentation for Anomalies**:\n",
    "   - **Synthetic Anomaly Generation**: Created synthetic anomalies by introducing noise or modifying patterns, including complex anomalies that involve accelerometer and gyroscope data.\n",
    "   - **Integrate Synthetic Data**: Augmented the original dataset with synthetic anomalies, retrained Isolation Forest, and monitored detection efficacy.\n",
    "   - **Model Performance Comparison**: Compared model precision and recall between real and synthetic anomalies, documenting the impact on performance.\n",
    "\n",
    "2. **Visualization of Anomalies**:\n",
    "   - **Augmented Data Visualization**: Visualized synthetic anomalies to ensure correct identification as outliers.\n",
    "   - **Model Comparison**: Visualized differences in anomaly detection results between Isolation Forest and other models for interpretability and performance insights.\n",
    "\n",
    "3. **Simulation and Stress Testing**:\n",
    "   - **Simulate and Test Anomalies**: Conducted robustness testing by simulating high-frequency and varied types of anomalies to evaluate the model's detection rate and resilience.\n",
    "   - **Document Model Responses**: Tracked Isolation Forest’s performance under stress, noting detection weaknesses and response to stress conditions.\n",
    "   - **Compile Findings**: Summarized stress test outcomes, highlighting model strengths, weaknesses, and proposed enhancements for robustness.\n",
    "\n",
    "4. **Final Documentation**:\n",
    "   - **Stress Test Reporting**: Documented key insights from stress tests, offering actionable steps to improve model resilience against high-frequency anomalies.\n",
    "   - **Validation Report and Strategy Update**: Compiled validation findings and suggested updates to the anomaly detection strategy based on observed results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891ac19e",
   "metadata": {},
   "source": [
    "ABSENT - 12th to 15th November due to examination"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
