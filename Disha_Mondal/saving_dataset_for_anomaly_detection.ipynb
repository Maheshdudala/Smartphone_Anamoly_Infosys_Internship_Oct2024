{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4045d7f8-d807-41a6-b013-9af3678ad053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data Preview:\n",
      "   Longitude   Latitude  Speed  Distance      Time     Acc X     Acc Y  \\\n",
      "0  73.822661  18.501627    0.0       0.0  18-45-12 -0.271978  0.239697   \n",
      "1  73.822661  18.501627    0.0       0.0  18-45-12 -0.203242  0.330358   \n",
      "2  73.822661  18.501627    0.0       0.0  18-45-13 -0.052430  0.283010   \n",
      "3  73.822661  18.501627    0.0       0.0  18-45-13  0.046597  0.181215   \n",
      "4  73.822661  18.501627    0.0       0.0  18-45-13  0.038631  0.341300   \n",
      "\n",
      "      Acc Z  Heading    gyro_x    gyro_y    gyro_z  \n",
      "0 -0.870133    352.0  0.022826 -0.035573  0.012482  \n",
      "1  0.822501    352.0 -0.024821  0.045672 -0.016229  \n",
      "2 -0.348588    352.0 -0.071247  0.027346 -0.015618  \n",
      "3 -1.068336    352.0  0.028324 -0.009306 -0.015007  \n",
      "4  0.365102    352.0  0.022215 -0.015414  0.014315  \n",
      "Accelerometer and Gyroscope Data Preview:\n",
      "      Acc X     Acc Y     Acc Z    gyro_x    gyro_y    gyro_z  label\n",
      "0  0.046402 -0.137178 -0.282934 -0.036306 -0.008226 -0.023416      0\n",
      "1 -0.136978  0.365242  0.108889  0.035776 -0.009448  0.009570      0\n",
      "2 -0.045355 -0.103340 -0.534985 -0.011871 -0.027774  0.003462      0\n",
      "3  0.242089  0.072761 -0.350396 -0.017980  0.002769 -0.005091      0\n",
      "4 -0.230234  0.011765 -0.494085  0.011342  0.003380  0.006516      0\n",
      "Final adjusted dataset saved to infosys/data/final_adjusted_crowd_dataset.csv\n",
      "Adjustments made:\n",
      "- Merged data from two files.\n",
      "- Added accelerometer and gyroscope data with labels.\n",
      "- Speed scaled down by factor of 0.2 to simulate human walking/running speeds.\n",
      "- Labels adjusted (0: normal behavior, 1: anomalous behavior).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Unzip the uploaded file\n",
    "zip_file_path = '5stn873wft-1.zip'\n",
    "unzip_dir = 'infosys/data/unzipped_data/'\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unzip_dir)\n",
    "\n",
    "# Load the individual files\n",
    "file1_path = os.path.join(unzip_dir, '1_20210317_184512.csv')\n",
    "file2_path = os.path.join(unzip_dir, '2_20210317_171452.csv')\n",
    "\n",
    "df1 = pd.read_csv(file1_path)\n",
    "df2 = pd.read_csv(file2_path)\n",
    "\n",
    "# Merge the two files based on a common key, such as Time (assuming Time is the common column)\n",
    "df_merged = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Load the accelerometer and gyroscope data with labels from 3_FinalDatasetCsv.csv\n",
    "dataset_path = os.path.join(unzip_dir, '3_FinalDatasetCsv.csv')\n",
    "df_acc_gyro = pd.read_csv(dataset_path)\n",
    "\n",
    "# Check the first few rows to ensure the data structure\n",
    "print(\"Merged Data Preview:\")\n",
    "print(df_merged.head())\n",
    "\n",
    "print(\"Accelerometer and Gyroscope Data Preview:\")\n",
    "print(df_acc_gyro.head())\n",
    "\n",
    "# Ensure the number of rows between merged data and acc/gyro data match\n",
    "# If there's a mismatch, you might need to align based on timestamps or trim rows accordingly\n",
    "\n",
    "# Join the datasets (assuming they are aligned by row or time)\n",
    "# For now, we assume they are aligned by index (row-wise) since no specific common key is given\n",
    "df_final = df_merged.copy()\n",
    "df_final[['Acc X', 'Acc Y', 'Acc Z', 'gyro_x', 'gyro_y', 'gyro_z', 'label']] = df_acc_gyro[['Acc X', 'Acc Y', 'Acc Z', 'gyro_x', 'gyro_y', 'gyro_z', 'label']]\n",
    "\n",
    "# Adjust speed for human context\n",
    "speed_scale_factor = 0.2  # Adjust this based on your assumptions\n",
    "df_final['Speed'] = df_final['Speed'] * speed_scale_factor\n",
    "\n",
    "# Adjust labels (0: normal, 1: anomalous behavior)\n",
    "df_final['label'] = df_final['label'].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "# Save the final adjusted dataset\n",
    "adjusted_dataset_path = 'infosys/data/final_adjusted_crowd_dataset.csv'\n",
    "df_final.to_csv(adjusted_dataset_path, index=False)\n",
    "\n",
    "print(f\"Final adjusted dataset saved to {adjusted_dataset_path}\")\n",
    "\n",
    "# Summary of Adjustments\n",
    "print(\"Adjustments made:\")\n",
    "print(\"- Merged data from two files.\")\n",
    "print(\"- Added accelerometer and gyroscope data with labels.\")\n",
    "print(\"- Speed scaled down by factor of 0.2 to simulate human walking/running speeds.\")\n",
    "print(\"- Labels adjusted (0: normal behavior, 1: anomalous behavior).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31df8fe2-c86f-4bc3-94da-8a0612652cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9de170-8aba-4891-b85b-37ce512dcd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imbalanced-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874d4748-5882-4a48-b962-7fb39574e900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load the dataset\n",
    "file_path = './data/final_adjusted_crowd_dataset.csv'  # Replace with the actual file path\n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure that the 'Time' column is properly formatted\n",
    "print('Converting Time column to datetime format...')\n",
    "\n",
    "# Replace any hyphens with colons to match the HH:MM:SS format\n",
    "dataset['Time'] = dataset['Time'].str.replace('-', ':')\n",
    "\n",
    "# Now convert the column to datetime, assuming the corrected format is HH:MM:SS\n",
    "dataset['Time'] = pd.to_datetime(dataset['Time'], format='%H:%M:%S', errors='coerce')\n",
    "\n",
    "# Convert 'Time' to seconds since the start of the day\n",
    "dataset['Time_in_seconds'] = dataset['Time'].dt.hour * 3600 + dataset['Time'].dt.minute * 60 + dataset['Time'].dt.second\n",
    "\n",
    "# Drop the original 'Time' column and use 'Time_in_seconds' instead\n",
    "X = dataset.drop(columns=['label', 'Time'])  # Use 'Time_in_seconds' and other features\n",
    "y = dataset['label']\n",
    "\n",
    "# Applying SMOTE to oversample the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Convert 'Time_in_seconds' back to 'HH:MM:SS' format\n",
    "X_resampled['Time'] = X_resampled['Time_in_seconds'].apply(lambda x: str(timedelta(seconds=int(x))))\n",
    "\n",
    "# Drop the 'Time_in_seconds' column after conversion\n",
    "X_resampled = X_resampled.drop(columns=['Time_in_seconds'])\n",
    "\n",
    "# Combine the resampled data back into a dataframe\n",
    "resampled_dataset = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "# Save the resampled dataset\n",
    "resampled_dataset.to_csv('resampled_crowd_dataset_with_time_converted.csv', index=False)\n",
    "print(\"Resampled dataset saved as 'resampled_crowd_dataset_with_time_converted.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
